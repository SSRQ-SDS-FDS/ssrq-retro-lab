{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssrq_retro_lab.config import PROJECT_ROOT\n",
    "from ssrq_retro_lab.utils import split_exports\n",
    "from ssrq_retro_lab.repository import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "\n",
    "SPLITTED_DATA_PATH = PROJECT_ROOT / 'data/ZG/master'\n",
    "\n",
    "makedirs(SPLITTED_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for export in (PROJECT_ROOT / 'data/export').glob('*.txt'):\n",
    "    content_parts = split_exports.split_content(reader.TextReader(export).read())\n",
    "    volume = export.name.removesuffix('.txt')\n",
    "\n",
    "    for i, part in enumerate(content_parts):\n",
    "        with open(SPLITTED_DATA_PATH / f'{volume}_{i}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             file  lines  words\n",
      "0    ZG_1_1_0.txt     35    286\n",
      "1    ZG_1_1_1.txt     37    336\n",
      "2   ZG_1_1_10.txt     40    391\n",
      "3   ZG_1_1_11.txt     32    250\n",
      "4   ZG_1_1_12.txt     38    317\n",
      "5   ZG_1_1_13.txt     40    350\n",
      "6   ZG_1_1_14.txt     40    363\n",
      "7   ZG_1_1_15.txt     40    362\n",
      "8    ZG_1_1_2.txt     36    344\n",
      "9    ZG_1_1_3.txt     39    480\n",
      "10   ZG_1_1_4.txt     40    493\n",
      "11   ZG_1_1_5.txt     39    490\n",
      "12   ZG_1_1_6.txt     42    511\n",
      "13   ZG_1_1_7.txt     40    408\n",
      "14   ZG_1_1_8.txt     39    348\n",
      "15   ZG_1_1_9.txt     40    385\n",
      "16   ZG_1_2_0.txt     35    333\n",
      "17   ZG_1_2_1.txt     40    286\n",
      "18  ZG_1_2_10.txt     39    437\n",
      "19  ZG_1_2_11.txt     37    348\n",
      "20  ZG_1_2_12.txt     39    391\n",
      "21  ZG_1_2_13.txt     39    321\n",
      "22  ZG_1_2_14.txt     40    375\n",
      "23  ZG_1_2_15.txt     40    366\n",
      "24  ZG_1_2_16.txt     38    351\n",
      "25  ZG_1_2_17.txt     39    325\n",
      "26  ZG_1_2_18.txt     38    368\n",
      "27  ZG_1_2_19.txt     38    364\n",
      "28   ZG_1_2_2.txt     36    335\n",
      "29  ZG_1_2_20.txt     39    384\n",
      "30  ZG_1_2_21.txt     37    323\n",
      "31  ZG_1_2_22.txt     38    315\n",
      "32  ZG_1_2_23.txt     39    350\n",
      "33  ZG_1_2_24.txt     38    321\n",
      "34  ZG_1_2_25.txt     40    410\n",
      "35  ZG_1_2_26.txt     37    355\n",
      "36  ZG_1_2_27.txt     40    404\n",
      "37  ZG_1_2_28.txt     36    283\n",
      "38  ZG_1_2_29.txt     35    258\n",
      "39   ZG_1_2_3.txt     38    301\n",
      "40  ZG_1_2_30.txt     38    380\n",
      "41  ZG_1_2_31.txt     39    347\n",
      "42  ZG_1_2_32.txt     39    311\n",
      "43  ZG_1_2_33.txt     38    339\n",
      "44  ZG_1_2_34.txt     39    360\n",
      "45  ZG_1_2_35.txt     37    317\n",
      "46  ZG_1_2_36.txt     37    303\n",
      "47   ZG_1_2_4.txt     35    268\n",
      "48   ZG_1_2_5.txt     40    413\n",
      "49   ZG_1_2_6.txt     41    444\n",
      "50   ZG_1_2_7.txt     39    398\n",
      "51   ZG_1_2_8.txt     39    443\n",
      "52   ZG_1_2_9.txt     40    466\n"
     ]
    }
   ],
   "source": [
    "def get_stats(file):\n",
    "    content = reader.TextReader(file).read()\n",
    "    lines = content.count('\\n') + 1\n",
    "    words = len(content.split())\n",
    "    return {'file': file.name, 'lines': lines, 'words': words}\n",
    "\n",
    "df = pd.DataFrame(columns=['file', 'lines', 'words'], data=[get_stats(file) for file in SPLITTED_DATA_PATH.glob('*.txt')]).sort_values('file', ignore_index=True)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19207\n"
     ]
    }
   ],
   "source": [
    "# sum of words\n",
    "print(df.words.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
