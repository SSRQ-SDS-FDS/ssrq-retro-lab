{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Mistral 7B Instruct for OCR Correction\n",
    "\n",
    "Purpose of this notebook:\n",
    "- create training data (`.jsonl`) for a fine-tuned LLM\n",
    "- fine-tuning will be done locally (on a MAC) using the [`mlx`](https://github.com/ml-explore)-library\n",
    "\n",
    "Inspired by:\n",
    "[https://apeatling.com/articles/simple-guide-to-local-llm-fine-tuning-on-a-mac-with-mlx/](https://apeatling.com/articles/simple-guide-to-local-llm-fine-tuning-on-a-mac-with-mlx/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ssrq_retro_lab.config import PROJECT_ROOT, ZG_DATA_ROOT\n",
    "from ssrq_retro_lab.pipeline.templates.utils import render_template\n",
    "from ssrq_retro_lab.repository.writer import JSONLWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_training_df = pd.read_pickle(\n",
    "    PROJECT_ROOT / \"notebooks\" / \"pkl_cache\" / \"ocr_line_based_training.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts: list[str] = [\n",
    "    render_template(\n",
    "        \"mistral_ocr_training_v1.jinja2\", source=row[\"source\"], target=row[\"target\"]\n",
    "    )\n",
    "    for _, row in ocr_training_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the seed to 42 for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(prompts)\n",
    "\n",
    "test_prompts = prompts[:17]\n",
    "\n",
    "train, validation = train_test_split(\n",
    "    prompts[17:], test_size=0.2, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have created 80% train, 20% validation and 17 test prompts\n",
    "len(train), len(validation), len(test_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONLWriter(ZG_DATA_ROOT / \"training_data\" / \"mistral_ocr\" / \"test.jsonl\").write(\n",
    "    content=[{\"text\": p} for p in test_prompts]\n",
    ")\n",
    "\n",
    "JSONLWriter(ZG_DATA_ROOT / \"training_data\" / \"mistral_ocr\" / \"train.jsonl\").write(\n",
    "    content=[{\"text\": p} for p in train]\n",
    ")\n",
    "\n",
    "JSONLWriter(ZG_DATA_ROOT / \"training_data\" / \"mistral_ocr\" / \"valid.jsonl\").write(\n",
    "    content=[{\"text\": p} for p in validation]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Loading pretrained model\n",
      "Fetching 5 files:   0%|                                   | 0/5 [00:00<?, ?it/s]\n",
      "config.json: 100%|█████████████████████████| 2.26k/2.26k [00:00<00:00, 11.2MB/s]\u001b[A\n",
      "Fetching 5 files:  20%|█████▍                     | 1/5 [00:00<00:01,  3.43it/s]\n",
      "tokenizer.json:   0%|                               | 0.00/1.80M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████| 1.46k/1.46k [00:00<00:00, 8.49MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 414/414 [00:00<00:00, 2.38MB/s]\u001b[A\u001b[A\n",
      "Fetching 5 files:  40%|██████████▊                | 2/5 [00:00<00:00,  4.30it/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 3.56MB/s]\u001b[A\n",
      "Fetching 5 files:  60%|████████████████▏          | 3/5 [00:00<00:00,  3.67it/s]\n",
      "weights.00.safetensors:   0%|                       | 0.00/4.26G [00:00<?, ?B/s]\u001b[A\n",
      "weights.00.safetensors:   0%|              | 10.5M/4.26G [00:00<05:27, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:   0%|              | 21.0M/4.26G [00:01<05:22, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   1%|              | 31.5M/4.26G [00:02<05:19, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   1%|▏             | 41.9M/4.26G [00:03<05:18, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   1%|▏             | 52.4M/4.26G [00:03<05:20, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   1%|▏             | 62.9M/4.26G [00:04<05:18, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   2%|▏             | 73.4M/4.26G [00:05<05:16, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   2%|▎             | 83.9M/4.26G [00:06<05:15, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   2%|▎             | 94.4M/4.26G [00:07<05:14, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   2%|▎              | 105M/4.26G [00:07<05:13, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   3%|▍              | 115M/4.26G [00:08<05:12, 13.3MB/s]\u001b[A\n",
      "weights.00.safetensors:   3%|▍              | 126M/4.26G [00:09<05:11, 13.3MB/s]\u001b[A\n",
      "weights.00.safetensors:   3%|▍              | 136M/4.26G [00:10<05:36, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:   3%|▌              | 147M/4.26G [00:11<05:28, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:   4%|▌              | 157M/4.26G [00:12<05:22, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:   4%|▌              | 168M/4.26G [00:12<05:17, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:   4%|▋              | 178M/4.26G [00:13<05:14, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:   4%|▋              | 189M/4.26G [00:14<05:12, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   5%|▋              | 199M/4.26G [00:15<05:10, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   5%|▋              | 210M/4.26G [00:16<05:08, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   5%|▊              | 220M/4.26G [00:16<05:06, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   5%|▊              | 231M/4.26G [00:17<05:06, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   6%|▊              | 241M/4.26G [00:18<05:04, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   6%|▉              | 252M/4.26G [00:19<05:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   6%|▉              | 262M/4.26G [00:20<05:25, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:   6%|▉              | 273M/4.26G [00:21<05:17, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:   7%|▉              | 283M/4.26G [00:21<05:11, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:   7%|█              | 294M/4.26G [00:22<05:07, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:   7%|█              | 304M/4.26G [00:23<05:04, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:   7%|█              | 315M/4.26G [00:24<05:01, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   8%|█▏             | 325M/4.26G [00:24<04:59, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   8%|█▏             | 336M/4.26G [00:25<04:58, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   8%|█▏             | 346M/4.26G [00:26<04:57, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:   8%|█▎             | 357M/4.26G [00:27<04:56, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   9%|█▎             | 367M/4.26G [00:28<04:55, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   9%|█▎             | 377M/4.26G [00:28<04:54, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   9%|█▎             | 388M/4.26G [00:29<04:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:   9%|█▍             | 398M/4.26G [00:30<05:15, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  10%|█▍             | 409M/4.26G [00:31<05:07, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  10%|█▍             | 419M/4.26G [00:32<05:01, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  10%|█▌             | 430M/4.26G [00:33<04:57, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  10%|█▌             | 440M/4.26G [00:33<04:54, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  11%|█▌             | 451M/4.26G [00:34<04:51, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  11%|█▌             | 461M/4.26G [00:35<04:49, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  11%|█▋             | 472M/4.26G [00:36<04:47, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  11%|█▋             | 482M/4.26G [00:37<04:46, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  12%|█▋             | 493M/4.26G [00:37<04:45, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  12%|█▊             | 503M/4.26G [00:38<04:44, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  12%|█▊             | 514M/4.26G [00:39<04:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  12%|█▊             | 524M/4.26G [00:40<04:42, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  13%|█▉             | 535M/4.26G [00:41<04:41, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  13%|█▉             | 545M/4.26G [00:41<04:40, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  13%|█▉             | 556M/4.26G [00:42<04:39, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  13%|█▉             | 566M/4.26G [00:43<04:39, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  14%|██             | 577M/4.26G [00:44<04:38, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  14%|██             | 587M/4.26G [00:44<04:37, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  14%|██             | 598M/4.26G [00:45<04:36, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  14%|██▏            | 608M/4.26G [00:46<04:35, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  15%|██▏            | 619M/4.26G [00:47<04:35, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  15%|██▏            | 629M/4.26G [00:48<04:34, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  15%|██▎            | 640M/4.26G [00:49<04:54, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  15%|██▎            | 650M/4.26G [00:49<04:47, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  15%|██▎            | 661M/4.26G [00:50<04:42, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  16%|██▎            | 671M/4.26G [00:51<04:38, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  16%|██▍            | 682M/4.26G [00:52<04:35, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  16%|██▍            | 692M/4.26G [00:53<04:33, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  16%|██▍            | 703M/4.26G [00:53<04:31, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  17%|██▌            | 713M/4.26G [00:54<04:30, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  17%|██▌            | 724M/4.26G [00:55<04:28, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  17%|██▌            | 734M/4.26G [00:56<04:27, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  17%|██▌            | 744M/4.26G [00:57<04:27, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  18%|██▋            | 755M/4.26G [00:57<04:25, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  18%|██▋            | 765M/4.26G [00:58<04:24, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  18%|██▋            | 776M/4.26G [00:59<04:44, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  18%|██▊            | 786M/4.26G [01:00<04:37, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  19%|██▊            | 797M/4.26G [01:01<04:32, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  19%|██▊            | 807M/4.26G [01:02<04:28, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  19%|██▉            | 818M/4.26G [01:02<04:25, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  19%|██▉            | 828M/4.26G [01:03<04:22, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  20%|██▉            | 839M/4.26G [01:04<04:21, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  20%|██▉            | 849M/4.26G [01:05<04:19, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  20%|███            | 860M/4.26G [01:05<04:18, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  20%|███            | 870M/4.26G [01:06<04:17, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  21%|███            | 881M/4.26G [01:07<04:15, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  21%|███▏           | 891M/4.26G [01:08<04:15, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  21%|███▏           | 902M/4.26G [01:09<04:20, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  21%|███▏           | 912M/4.26G [01:10<04:30, 12.4MB/s]\u001b[A\n",
      "weights.00.safetensors:  22%|███▏           | 923M/4.26G [01:10<04:24, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  22%|███▎           | 933M/4.26G [01:11<04:20, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  22%|███▎           | 944M/4.26G [01:12<04:16, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  22%|███▎           | 954M/4.26G [01:13<04:14, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  23%|███▍           | 965M/4.26G [01:14<04:12, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  23%|███▍           | 975M/4.26G [01:14<04:10, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  23%|███▍           | 986M/4.26G [01:15<04:09, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  23%|███▌           | 996M/4.26G [01:16<04:09, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  24%|███▎          | 1.01G/4.26G [01:17<04:07, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  24%|███▎          | 1.02G/4.26G [01:18<04:06, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  24%|███▍          | 1.03G/4.26G [01:18<04:05, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  24%|███▍          | 1.04G/4.26G [01:19<04:04, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  25%|███▍          | 1.05G/4.26G [01:20<04:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  25%|███▍          | 1.06G/4.26G [01:21<04:02, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  25%|███▌          | 1.07G/4.26G [01:22<04:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  25%|███▌          | 1.08G/4.26G [01:22<04:00, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  26%|███▌          | 1.09G/4.26G [01:23<03:59, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  26%|███▌          | 1.10G/4.26G [01:24<03:58, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  26%|███▋          | 1.11G/4.26G [01:25<04:16, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  26%|███▋          | 1.12G/4.26G [01:26<04:09, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  27%|███▋          | 1.13G/4.26G [01:27<04:05, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  27%|███▊          | 1.14G/4.26G [01:27<04:01, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  27%|███▊          | 1.15G/4.26G [01:28<03:59, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  27%|███▊          | 1.16G/4.26G [01:29<03:57, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  28%|███▊          | 1.17G/4.26G [01:30<03:55, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  28%|███▉          | 1.18G/4.26G [01:30<03:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  28%|███▉          | 1.20G/4.26G [01:31<03:52, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  28%|███▉          | 1.21G/4.26G [01:32<03:51, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  29%|███▉          | 1.22G/4.26G [01:33<03:50, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  29%|████          | 1.23G/4.26G [01:34<03:49, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  29%|████          | 1.24G/4.26G [01:34<03:48, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  29%|████          | 1.25G/4.26G [01:35<04:05, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  30%|████▏         | 1.26G/4.26G [01:36<03:59, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  30%|████▏         | 1.27G/4.26G [01:37<03:54, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  30%|████▏         | 1.28G/4.26G [01:38<03:51, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  30%|████▏         | 1.29G/4.26G [01:39<03:48, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  31%|████▎         | 1.30G/4.26G [01:39<03:46, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  31%|████▎         | 1.31G/4.26G [01:40<03:44, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  31%|████▎         | 1.32G/4.26G [01:41<03:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  31%|████▎         | 1.33G/4.26G [01:42<03:42, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  31%|████▍         | 1.34G/4.26G [01:43<03:41, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  32%|████▍         | 1.35G/4.26G [01:43<03:40, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  32%|████▍         | 1.36G/4.26G [01:44<03:39, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  32%|████▌         | 1.37G/4.26G [01:45<03:47, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  32%|████▌         | 1.38G/4.26G [01:46<03:52, 12.4MB/s]\u001b[A\n",
      "weights.00.safetensors:  33%|████▌         | 1.39G/4.26G [01:47<03:46, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  33%|████▌         | 1.41G/4.26G [01:48<03:42, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  33%|████▋         | 1.42G/4.26G [01:48<03:40, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  33%|████▋         | 1.43G/4.26G [01:49<03:37, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  34%|████▋         | 1.44G/4.26G [01:50<03:35, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  34%|████▊         | 1.45G/4.26G [01:51<03:34, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  34%|████▊         | 1.46G/4.26G [01:51<03:33, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  34%|████▊         | 1.47G/4.26G [01:52<03:32, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  35%|████▊         | 1.48G/4.26G [01:53<03:30, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  35%|████▉         | 1.49G/4.26G [01:54<03:29, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  35%|████▉         | 1.50G/4.26G [01:55<03:29, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  35%|████▉         | 1.51G/4.26G [01:56<03:44, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  36%|████▉         | 1.52G/4.26G [01:56<03:38, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  36%|█████         | 1.53G/4.26G [01:57<03:34, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  36%|█████         | 1.54G/4.26G [01:58<03:31, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  36%|█████         | 1.55G/4.26G [01:59<03:28, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  37%|█████▏        | 1.56G/4.26G [02:00<03:26, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  37%|█████▏        | 1.57G/4.26G [02:00<03:24, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  37%|█████▏        | 1.58G/4.26G [02:01<03:23, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  37%|█████▏        | 1.59G/4.26G [02:02<03:22, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  38%|█████▎        | 1.60G/4.26G [02:03<03:21, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  38%|█████▎        | 1.61G/4.26G [02:04<03:20, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  38%|█████▎        | 1.63G/4.26G [02:04<03:21, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  38%|█████▎        | 1.64G/4.26G [02:05<03:19, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  39%|█████▍        | 1.65G/4.26G [02:06<03:33, 12.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  39%|█████▍        | 1.66G/4.26G [02:07<03:28, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  39%|█████▍        | 1.67G/4.26G [02:08<03:23, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  39%|█████▌        | 1.68G/4.26G [02:09<03:20, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  40%|█████▌        | 1.69G/4.26G [02:09<03:18, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  40%|█████▌        | 1.70G/4.26G [02:10<03:16, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  40%|█████▌        | 1.71G/4.26G [02:11<03:14, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  40%|█████▋        | 1.72G/4.26G [02:12<03:13, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  41%|█████▋        | 1.73G/4.26G [02:13<03:12, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  41%|█████▋        | 1.74G/4.26G [02:13<03:11, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  41%|█████▊        | 1.75G/4.26G [02:14<03:10, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  41%|█████▊        | 1.76G/4.26G [02:15<03:09, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  42%|█████▊        | 1.77G/4.26G [02:16<03:22, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  42%|█████▊        | 1.78G/4.26G [02:17<03:17, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  42%|█████▉        | 1.79G/4.26G [02:17<03:13, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  42%|█████▉        | 1.80G/4.26G [02:18<03:10, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  43%|█████▉        | 1.81G/4.26G [02:19<03:08, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  43%|█████▉        | 1.82G/4.26G [02:20<03:06, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  43%|██████        | 1.84G/4.26G [02:21<03:05, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  43%|██████        | 1.85G/4.26G [02:21<03:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  44%|██████        | 1.86G/4.26G [02:22<03:02, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  44%|██████▏       | 1.87G/4.26G [02:23<03:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  44%|██████▏       | 1.88G/4.26G [02:24<03:00, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  44%|██████▏       | 1.89G/4.26G [02:25<02:59, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  45%|██████▏       | 1.90G/4.26G [02:25<02:58, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  45%|██████▎       | 1.91G/4.26G [02:26<02:58, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  45%|██████▎       | 1.92G/4.26G [02:27<02:57, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  45%|██████▎       | 1.93G/4.26G [02:28<02:56, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  46%|██████▎       | 1.94G/4.26G [02:29<02:55, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  46%|██████▍       | 1.95G/4.26G [02:29<02:54, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  46%|██████▍       | 1.96G/4.26G [02:30<02:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  46%|██████▍       | 1.97G/4.26G [02:31<02:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  46%|██████▌       | 1.98G/4.26G [02:32<02:52, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  47%|██████▌       | 1.99G/4.26G [02:33<02:51, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  47%|██████▌       | 2.00G/4.26G [02:33<02:50, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  47%|██████▌       | 2.01G/4.26G [02:34<02:49, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  47%|██████▋       | 2.02G/4.26G [02:35<03:02, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  48%|██████▋       | 2.03G/4.26G [02:36<02:57, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  48%|██████▋       | 2.04G/4.26G [02:37<02:53, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  48%|██████▊       | 2.06G/4.26G [02:37<02:51, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  48%|██████▊       | 2.07G/4.26G [02:38<02:49, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  49%|██████▊       | 2.08G/4.26G [02:39<02:47, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  49%|██████▊       | 2.09G/4.26G [02:40<02:45, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  49%|██████▉       | 2.10G/4.26G [02:41<02:44, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  49%|██████▉       | 2.11G/4.26G [02:41<02:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  50%|██████▉       | 2.12G/4.26G [02:42<02:42, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  50%|██████▉       | 2.13G/4.26G [02:43<02:41, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  50%|███████       | 2.14G/4.26G [02:44<02:40, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  50%|███████       | 2.15G/4.26G [02:45<02:39, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  51%|███████       | 2.16G/4.26G [02:46<02:51, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  51%|███████▏      | 2.17G/4.26G [02:46<02:46, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  51%|███████▏      | 2.18G/4.26G [02:47<02:43, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  51%|███████▏      | 2.19G/4.26G [02:48<02:40, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  52%|███████▏      | 2.20G/4.26G [02:49<02:38, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  52%|███████▎      | 2.21G/4.26G [02:50<02:36, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  52%|███████▎      | 2.22G/4.26G [02:50<02:35, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  52%|███████▎      | 2.23G/4.26G [02:51<02:34, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  53%|███████▎      | 2.24G/4.26G [02:52<02:33, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  53%|███████▍      | 2.25G/4.26G [02:53<02:32, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  53%|███████▍      | 2.26G/4.26G [02:54<02:31, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  53%|███████▍      | 2.28G/4.26G [02:54<02:30, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  54%|███████▌      | 2.29G/4.26G [02:55<02:29, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  54%|███████▌      | 2.30G/4.26G [02:56<02:40, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  54%|███████▌      | 2.31G/4.26G [02:57<02:35, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  54%|███████▌      | 2.32G/4.26G [02:58<02:32, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  55%|███████▋      | 2.33G/4.26G [02:58<02:30, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  55%|███████▋      | 2.34G/4.26G [02:59<02:28, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  55%|███████▋      | 2.35G/4.26G [03:00<02:26, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  55%|███████▋      | 2.36G/4.26G [03:01<02:25, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  56%|███████▊      | 2.37G/4.26G [03:02<02:23, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  56%|███████▊      | 2.38G/4.26G [03:02<02:22, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  56%|███████▊      | 2.39G/4.26G [03:03<02:21, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  56%|███████▉      | 2.40G/4.26G [03:04<02:20, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  57%|███████▉      | 2.41G/4.26G [03:05<02:19, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  57%|███████▉      | 2.42G/4.26G [03:06<02:29, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  57%|███████▉      | 2.43G/4.26G [03:07<02:25, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  57%|████████      | 2.44G/4.26G [03:07<02:22, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  58%|████████      | 2.45G/4.26G [03:08<02:20, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  58%|████████      | 2.46G/4.26G [03:09<02:19, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  58%|████████▏     | 2.47G/4.26G [03:10<02:17, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  58%|████████▏     | 2.49G/4.26G [03:11<02:16, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  59%|████████▏     | 2.50G/4.26G [03:11<02:14, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  59%|████████▏     | 2.51G/4.26G [03:12<02:13, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  59%|████████▎     | 2.52G/4.26G [03:13<02:12, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  59%|████████▎     | 2.53G/4.26G [03:14<02:11, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  60%|████████▎     | 2.54G/4.26G [03:15<02:10, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  60%|████████▎     | 2.55G/4.26G [03:15<02:09, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  60%|████████▍     | 2.56G/4.26G [03:16<02:18, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  60%|████████▍     | 2.57G/4.26G [03:17<02:14, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  61%|████████▍     | 2.58G/4.26G [03:18<02:11, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  61%|████████▌     | 2.59G/4.26G [03:19<02:09, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  61%|████████▌     | 2.60G/4.26G [03:19<02:07, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  61%|████████▌     | 2.61G/4.26G [03:20<02:06, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  62%|████████▌     | 2.62G/4.26G [03:21<02:05, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  62%|████████▋     | 2.63G/4.26G [03:22<02:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  62%|████████▋     | 2.64G/4.26G [03:23<02:02, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  62%|████████▋     | 2.65G/4.26G [03:23<02:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  62%|████████▋     | 2.66G/4.26G [03:24<02:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  63%|████████▊     | 2.67G/4.26G [03:25<02:00, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  63%|████████▊     | 2.68G/4.26G [03:26<02:08, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  63%|████████▊     | 2.69G/4.26G [03:27<02:04, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  63%|████████▉     | 2.71G/4.26G [03:28<02:02, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  64%|████████▉     | 2.72G/4.26G [03:28<02:00, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  64%|████████▉     | 2.73G/4.26G [03:29<01:58, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  64%|████████▉     | 2.74G/4.26G [03:30<01:56, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  64%|█████████     | 2.75G/4.26G [03:31<01:55, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  65%|█████████     | 2.76G/4.26G [03:32<01:54, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  65%|█████████     | 2.77G/4.26G [03:32<01:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  65%|█████████▏    | 2.78G/4.26G [03:33<01:52, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  65%|█████████▏    | 2.79G/4.26G [03:34<01:51, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  66%|█████████▏    | 2.80G/4.26G [03:35<01:50, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  66%|█████████▏    | 2.81G/4.26G [03:36<01:49, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  66%|█████████▎    | 2.82G/4.26G [03:37<01:57, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  66%|█████████▎    | 2.83G/4.26G [03:37<01:53, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  67%|█████████▎    | 2.84G/4.26G [03:38<01:51, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  67%|█████████▎    | 2.85G/4.26G [03:39<01:49, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  67%|█████████▍    | 2.86G/4.26G [03:40<01:47, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  67%|█████████▍    | 2.87G/4.26G [03:40<01:46, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  68%|█████████▍    | 2.88G/4.26G [03:41<01:45, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  68%|█████████▌    | 2.89G/4.26G [03:42<01:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  68%|█████████▌    | 2.90G/4.26G [03:43<01:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  68%|█████████▌    | 2.92G/4.26G [03:44<01:42, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  69%|█████████▌    | 2.93G/4.26G [03:44<01:41, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  69%|█████████▋    | 2.94G/4.26G [03:45<01:40, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  69%|█████████▋    | 2.95G/4.26G [03:46<01:39, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  69%|█████████▋    | 2.96G/4.26G [03:47<01:46, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  70%|█████████▋    | 2.97G/4.26G [03:48<01:43, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  70%|█████████▊    | 2.98G/4.26G [03:49<01:40, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  70%|█████████▊    | 2.99G/4.26G [03:49<01:38, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  70%|█████████▊    | 3.00G/4.26G [03:50<01:37, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  71%|█████████▉    | 3.01G/4.26G [03:51<01:35, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  71%|█████████▉    | 3.02G/4.26G [03:52<01:34, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  71%|█████████▉    | 3.03G/4.26G [03:53<01:33, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  71%|█████████▉    | 3.04G/4.26G [03:53<01:32, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  72%|██████████    | 3.05G/4.26G [03:54<01:31, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  72%|██████████    | 3.06G/4.26G [03:55<01:30, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  72%|██████████    | 3.07G/4.26G [03:56<01:30, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  72%|██████████▏   | 3.08G/4.26G [03:57<01:36, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  73%|██████████▏   | 3.09G/4.26G [03:58<01:33, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  73%|██████████▏   | 3.10G/4.26G [03:58<01:30, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  73%|██████████▏   | 3.11G/4.26G [03:59<01:29, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  73%|██████████▎   | 3.12G/4.26G [04:00<01:27, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  74%|██████████▎   | 3.14G/4.26G [04:01<01:26, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  74%|██████████▎   | 3.15G/4.26G [04:02<01:25, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  74%|██████████▎   | 3.16G/4.26G [04:02<01:24, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  74%|██████████▍   | 3.17G/4.26G [04:03<01:23, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  75%|██████████▍   | 3.18G/4.26G [04:04<01:22, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  75%|██████████▍   | 3.19G/4.26G [04:05<01:21, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  75%|██████████▌   | 3.20G/4.26G [04:05<01:20, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  75%|██████████▌   | 3.21G/4.26G [04:06<01:19, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  76%|██████████▌   | 3.22G/4.26G [04:07<01:24, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  76%|██████████▌   | 3.23G/4.26G [04:08<01:22, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  76%|██████████▋   | 3.24G/4.26G [04:09<01:20, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  76%|██████████▋   | 3.25G/4.26G [04:10<01:18, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  77%|██████████▋   | 3.26G/4.26G [04:10<01:17, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  77%|██████████▋   | 3.27G/4.26G [04:11<01:16, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  77%|██████████▊   | 3.28G/4.26G [04:12<01:14, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  77%|██████████▊   | 3.29G/4.26G [04:13<01:13, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  77%|██████████▊   | 3.30G/4.26G [04:14<01:12, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  78%|██████████▉   | 3.31G/4.26G [04:14<01:11, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  78%|██████████▉   | 3.32G/4.26G [04:15<01:11, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  78%|██████████▉   | 3.33G/4.26G [04:16<01:10, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  78%|██████████▉   | 3.34G/4.26G [04:17<01:09, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  79%|███████████   | 3.36G/4.26G [04:18<01:13, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  79%|███████████   | 3.37G/4.26G [04:19<01:11, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  79%|███████████   | 3.38G/4.26G [04:19<01:09, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  79%|███████████   | 3.39G/4.26G [04:20<01:07, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  80%|███████████▏  | 3.40G/4.26G [04:21<01:06, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  80%|███████████▏  | 3.41G/4.26G [04:22<01:05, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  80%|███████████▏  | 3.42G/4.26G [04:23<01:04, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  80%|███████████▎  | 3.43G/4.26G [04:23<01:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  81%|███████████▎  | 3.44G/4.26G [04:24<01:02, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  81%|███████████▎  | 3.45G/4.26G [04:25<01:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  81%|███████████▎  | 3.46G/4.26G [04:26<01:00, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  81%|███████████▍  | 3.47G/4.26G [04:26<00:59, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  82%|███████████▍  | 3.48G/4.26G [04:27<00:59, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  82%|███████████▍  | 3.49G/4.26G [04:28<00:58, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  82%|███████████▌  | 3.50G/4.26G [04:29<00:57, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  82%|███████████▌  | 3.51G/4.26G [04:30<00:56, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  83%|███████████▌  | 3.52G/4.26G [04:30<00:55, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  83%|███████████▌  | 3.53G/4.26G [04:31<00:55, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  83%|███████████▋  | 3.54G/4.26G [04:32<00:54, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  83%|███████████▋  | 3.55G/4.26G [04:33<00:53, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  84%|███████████▋  | 3.57G/4.26G [04:34<00:52, 13.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  84%|███████████▋  | 3.58G/4.26G [04:34<00:51, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  84%|███████████▊  | 3.59G/4.26G [04:35<00:55, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  84%|███████████▊  | 3.60G/4.26G [04:36<00:52, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  85%|███████████▊  | 3.61G/4.26G [04:37<00:51, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  85%|███████████▉  | 3.62G/4.26G [04:38<00:50, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  85%|███████████▉  | 3.63G/4.26G [04:39<00:48, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  85%|███████████▉  | 3.64G/4.26G [04:39<00:47, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  86%|███████████▉  | 3.65G/4.26G [04:40<00:46, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  86%|████████████  | 3.66G/4.26G [04:41<00:45, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  86%|████████████  | 3.67G/4.26G [04:42<00:45, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  86%|████████████  | 3.68G/4.26G [04:43<00:44, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  87%|████████████  | 3.69G/4.26G [04:43<00:43, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  87%|████████████▏ | 3.70G/4.26G [04:44<00:42, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  87%|████████████▏ | 3.71G/4.26G [04:45<00:41, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  87%|████████████▏ | 3.72G/4.26G [04:46<00:44, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  88%|████████████▎ | 3.73G/4.26G [04:47<00:42, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  88%|████████████▎ | 3.74G/4.26G [04:48<00:40, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  88%|████████████▎ | 3.75G/4.26G [04:48<00:39, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  88%|████████████▎ | 3.76G/4.26G [04:49<00:38, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  89%|████████████▍ | 3.77G/4.26G [04:50<00:37, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  89%|████████████▍ | 3.79G/4.26G [04:51<00:36, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  89%|████████████▍ | 3.80G/4.26G [04:51<00:35, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  89%|████████████▌ | 3.81G/4.26G [04:52<00:34, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  90%|████████████▌ | 3.82G/4.26G [04:53<00:33, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  90%|████████████▌ | 3.83G/4.26G [04:54<00:32, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  90%|████████████▌ | 3.84G/4.26G [04:55<00:32, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  90%|████████████▋ | 3.85G/4.26G [04:55<00:31, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  91%|████████████▋ | 3.86G/4.26G [04:56<00:32, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors:  91%|████████████▋ | 3.87G/4.26G [04:57<00:31, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  91%|████████████▋ | 3.88G/4.26G [04:58<00:29, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  91%|████████████▊ | 3.89G/4.26G [04:59<00:28, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  92%|████████████▊ | 3.90G/4.26G [05:00<00:27, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  92%|████████████▊ | 3.91G/4.26G [05:00<00:26, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  92%|████████████▉ | 3.92G/4.26G [05:01<00:25, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  92%|████████████▉ | 3.93G/4.26G [05:02<00:25, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  92%|████████████▉ | 3.94G/4.26G [05:03<00:24, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  93%|████████████▉ | 3.95G/4.26G [05:04<00:23, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  93%|█████████████ | 3.96G/4.26G [05:04<00:22, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  93%|█████████████ | 3.97G/4.26G [05:05<00:21, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  93%|█████████████ | 3.98G/4.26G [05:06<00:22, 12.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  94%|█████████████ | 4.00G/4.26G [05:07<00:21, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  94%|█████████████▏| 4.01G/4.26G [05:08<00:20, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  94%|█████████████▏| 4.02G/4.26G [05:09<00:21, 11.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  94%|█████████████▏| 4.03G/4.26G [05:10<00:19, 12.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  95%|█████████████▎| 4.04G/4.26G [05:10<00:18, 12.4MB/s]\u001b[A\n",
      "weights.00.safetensors:  95%|█████████████▎| 4.05G/4.26G [05:11<00:17, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors:  95%|█████████████▎| 4.06G/4.26G [05:12<00:15, 12.8MB/s]\u001b[A\n",
      "weights.00.safetensors:  95%|█████████████▎| 4.07G/4.26G [05:13<00:14, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  96%|█████████████▍| 4.08G/4.26G [05:14<00:14, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  96%|█████████████▍| 4.09G/4.26G [05:14<00:13, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  96%|█████████████▍| 4.10G/4.26G [05:15<00:12, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  96%|█████████████▌| 4.11G/4.26G [05:16<00:12, 12.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  97%|█████████████▌| 4.12G/4.26G [05:17<00:11, 12.5MB/s]\u001b[A\n",
      "weights.00.safetensors:  97%|█████████████▌| 4.13G/4.26G [05:18<00:10, 12.7MB/s]\u001b[A\n",
      "weights.00.safetensors:  97%|█████████████▌| 4.14G/4.26G [05:19<00:09, 12.9MB/s]\u001b[A\n",
      "weights.00.safetensors:  97%|█████████████▋| 4.15G/4.26G [05:19<00:08, 13.0MB/s]\u001b[A\n",
      "weights.00.safetensors:  98%|█████████████▋| 4.16G/4.26G [05:20<00:07, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  98%|█████████████▋| 4.17G/4.26G [05:21<00:06, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  98%|█████████████▋| 4.18G/4.26G [05:22<00:05, 13.1MB/s]\u001b[A\n",
      "weights.00.safetensors:  98%|█████████████▊| 4.19G/4.26G [05:22<00:05, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  99%|█████████████▊| 4.20G/4.26G [05:23<00:04, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  99%|█████████████▊| 4.22G/4.26G [05:24<00:03, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  99%|█████████████▉| 4.23G/4.26G [05:25<00:02, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors:  99%|█████████████▉| 4.24G/4.26G [05:26<00:01, 13.2MB/s]\u001b[A\n",
      "weights.00.safetensors: 100%|█████████████▉| 4.25G/4.26G [05:27<00:01, 12.3MB/s]\u001b[A\n",
      "weights.00.safetensors: 100%|█████████████▉| 4.26G/4.26G [05:27<00:00, 12.6MB/s]\u001b[A\n",
      "weights.00.safetensors: 100%|██████████████| 4.26G/4.26G [05:28<00:00, 13.0MB/s]\u001b[A\n",
      "Fetching 5 files: 100%|███████████████████████████| 5/5 [05:30<00:00, 66.15s/it]\n",
      "Total parameters 1243.189M\n",
      "Trainable parameters 0.852M\n",
      "Loading datasets\n",
      "Training\n",
      "Iter 1: Val loss 4.420, Val took 119.994s\n",
      "Iter 10: Train loss 3.847, It/sec 0.179, Tokens/sec 47.787\n",
      "Iter 20: Train loss 2.537, It/sec 0.174, Tokens/sec 44.742\n",
      "Iter 30: Train loss 1.606, It/sec 0.166, Tokens/sec 43.640\n",
      "Iter 40: Train loss 1.174, It/sec 0.174, Tokens/sec 43.067\n",
      "Iter 50: Train loss 1.100, It/sec 0.173, Tokens/sec 43.647\n",
      "Iter 60: Train loss 1.202, It/sec 0.167, Tokens/sec 43.176\n",
      "Iter 70: Train loss 1.210, It/sec 0.160, Tokens/sec 43.378\n",
      "Iter 80: Train loss 1.065, It/sec 0.170, Tokens/sec 42.942\n",
      "Iter 90: Train loss 1.071, It/sec 0.172, Tokens/sec 44.289\n",
      "Iter 100: Train loss 1.029, It/sec 0.167, Tokens/sec 42.949\n",
      "Iter 100: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 110: Train loss 1.046, It/sec 0.167, Tokens/sec 43.995\n",
      "Iter 120: Train loss 0.983, It/sec 0.171, Tokens/sec 43.887\n",
      "Iter 130: Train loss 1.029, It/sec 0.163, Tokens/sec 42.657\n",
      "Iter 140: Train loss 1.078, It/sec 0.168, Tokens/sec 42.900\n",
      "Iter 150: Train loss 1.012, It/sec 0.170, Tokens/sec 43.445\n",
      "Iter 160: Train loss 1.004, It/sec 0.174, Tokens/sec 43.884\n",
      "Iter 170: Train loss 1.080, It/sec 0.160, Tokens/sec 43.656\n",
      "Iter 180: Train loss 0.986, It/sec 0.168, Tokens/sec 43.313\n",
      "Iter 190: Train loss 1.106, It/sec 0.162, Tokens/sec 43.011\n",
      "Iter 200: Train loss 1.019, It/sec 0.164, Tokens/sec 42.216\n",
      "Iter 200: Val loss 0.987, Val took 121.287s\n",
      "Iter 200: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 210: Train loss 0.951, It/sec 0.168, Tokens/sec 43.035\n",
      "Iter 220: Train loss 0.958, It/sec 0.170, Tokens/sec 44.338\n",
      "Iter 230: Train loss 0.973, It/sec 0.169, Tokens/sec 43.482\n",
      "Iter 240: Train loss 0.982, It/sec 0.163, Tokens/sec 43.848\n",
      "Iter 250: Train loss 0.935, It/sec 0.166, Tokens/sec 43.197\n",
      "Iter 260: Train loss 0.915, It/sec 0.168, Tokens/sec 43.288\n",
      "Iter 270: Train loss 0.873, It/sec 0.174, Tokens/sec 44.048\n",
      "Iter 280: Train loss 0.962, It/sec 0.172, Tokens/sec 44.618\n",
      "Iter 290: Train loss 0.876, It/sec 0.168, Tokens/sec 42.764\n",
      "Iter 300: Train loss 0.983, It/sec 0.169, Tokens/sec 44.803\n",
      "Iter 300: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 310: Train loss 0.959, It/sec 0.164, Tokens/sec 44.254\n",
      "Iter 320: Train loss 1.011, It/sec 0.168, Tokens/sec 44.327\n",
      "Iter 330: Train loss 0.809, It/sec 0.179, Tokens/sec 43.072\n",
      "Iter 340: Train loss 0.928, It/sec 0.168, Tokens/sec 44.626\n",
      "Iter 350: Train loss 0.885, It/sec 0.163, Tokens/sec 42.059\n",
      "Iter 360: Train loss 0.917, It/sec 0.173, Tokens/sec 44.343\n",
      "Iter 370: Train loss 0.948, It/sec 0.164, Tokens/sec 41.791\n",
      "Iter 380: Train loss 0.904, It/sec 0.172, Tokens/sec 44.016\n",
      "Iter 390: Train loss 0.949, It/sec 0.162, Tokens/sec 43.773\n",
      "Iter 400: Train loss 0.880, It/sec 0.170, Tokens/sec 43.632\n",
      "Iter 400: Val loss 0.959, Val took 121.048s\n",
      "Iter 400: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 410: Train loss 0.895, It/sec 0.167, Tokens/sec 42.487\n",
      "Iter 420: Train loss 0.914, It/sec 0.166, Tokens/sec 42.483\n",
      "Iter 430: Train loss 1.009, It/sec 0.164, Tokens/sec 44.042\n",
      "Iter 440: Train loss 0.909, It/sec 0.171, Tokens/sec 44.605\n",
      "Iter 450: Train loss 0.942, It/sec 0.163, Tokens/sec 44.531\n",
      "Iter 460: Train loss 0.945, It/sec 0.171, Tokens/sec 42.793\n",
      "Iter 470: Train loss 0.984, It/sec 0.165, Tokens/sec 43.218\n",
      "Iter 480: Train loss 0.933, It/sec 0.170, Tokens/sec 44.232\n",
      "Iter 490: Train loss 0.793, It/sec 0.172, Tokens/sec 42.614\n",
      "Iter 500: Train loss 0.911, It/sec 0.168, Tokens/sec 44.038\n",
      "Iter 500: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 510: Train loss 0.884, It/sec 0.162, Tokens/sec 43.138\n",
      "Iter 520: Train loss 0.859, It/sec 0.171, Tokens/sec 43.471\n",
      "Iter 530: Train loss 0.891, It/sec 0.170, Tokens/sec 44.598\n",
      "Iter 540: Train loss 0.887, It/sec 0.171, Tokens/sec 44.983\n",
      "Iter 550: Train loss 0.844, It/sec 0.167, Tokens/sec 43.360\n",
      "Iter 560: Train loss 0.950, It/sec 0.165, Tokens/sec 44.723\n",
      "Iter 570: Train loss 0.881, It/sec 0.164, Tokens/sec 44.363\n",
      "Iter 580: Train loss 0.798, It/sec 0.169, Tokens/sec 43.768\n",
      "Iter 590: Train loss 0.907, It/sec 0.167, Tokens/sec 43.781\n",
      "Iter 600: Train loss 0.859, It/sec 0.176, Tokens/sec 45.192\n",
      "Iter 600: Val loss 0.932, Val took 121.664s\n",
      "Iter 600: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 610: Train loss 0.857, It/sec 0.172, Tokens/sec 44.145\n",
      "Iter 620: Train loss 0.819, It/sec 0.171, Tokens/sec 43.448\n",
      "Iter 630: Train loss 0.870, It/sec 0.163, Tokens/sec 42.254\n",
      "Iter 640: Train loss 0.819, It/sec 0.170, Tokens/sec 43.834\n",
      "Iter 650: Train loss 0.851, It/sec 0.161, Tokens/sec 41.831\n",
      "Iter 660: Train loss 0.803, It/sec 0.170, Tokens/sec 43.518\n",
      "Iter 670: Train loss 0.796, It/sec 0.171, Tokens/sec 43.927\n",
      "Iter 680: Train loss 0.850, It/sec 0.164, Tokens/sec 41.987\n",
      "Iter 690: Train loss 0.855, It/sec 0.169, Tokens/sec 43.283\n",
      "Iter 700: Train loss 0.871, It/sec 0.168, Tokens/sec 43.914\n",
      "Iter 700: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 710: Train loss 0.858, It/sec 0.171, Tokens/sec 44.260\n",
      "Iter 720: Train loss 0.840, It/sec 0.167, Tokens/sec 42.887\n",
      "Iter 730: Train loss 0.781, It/sec 0.170, Tokens/sec 43.460\n",
      "Iter 740: Train loss 0.765, It/sec 0.171, Tokens/sec 43.593\n",
      "Iter 750: Train loss 0.686, It/sec 0.172, Tokens/sec 42.648\n",
      "Iter 760: Train loss 0.732, It/sec 0.134, Tokens/sec 34.011\n",
      "Iter 770: Train loss 0.731, It/sec 0.146, Tokens/sec 37.725\n",
      "Iter 780: Train loss 0.824, It/sec 0.135, Tokens/sec 37.332\n",
      "Iter 790: Train loss 0.742, It/sec 0.145, Tokens/sec 37.737\n",
      "Iter 800: Train loss 0.635, It/sec 0.145, Tokens/sec 37.009\n",
      "Iter 800: Val loss 0.860, Val took 133.329s\n",
      "Iter 800: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 810: Train loss 0.785, It/sec 0.136, Tokens/sec 36.466\n",
      "Iter 820: Train loss 0.696, It/sec 0.138, Tokens/sec 35.391\n",
      "Iter 830: Train loss 0.774, It/sec 0.150, Tokens/sec 39.141\n",
      "Iter 840: Train loss 0.749, It/sec 0.151, Tokens/sec 40.169\n",
      "Iter 850: Train loss 0.724, It/sec 0.148, Tokens/sec 39.019\n",
      "Iter 860: Train loss 0.726, It/sec 0.154, Tokens/sec 39.362\n",
      "Iter 870: Train loss 0.743, It/sec 0.155, Tokens/sec 40.017\n",
      "Iter 880: Train loss 0.734, It/sec 0.146, Tokens/sec 37.576\n",
      "Iter 890: Train loss 0.770, It/sec 0.146, Tokens/sec 37.697\n",
      "Iter 900: Train loss 0.712, It/sec 0.143, Tokens/sec 36.425\n",
      "Iter 900: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n",
      "Iter 910: Train loss 0.752, It/sec 0.138, Tokens/sec 37.182\n",
      "Iter 920: Train loss 0.729, It/sec 0.149, Tokens/sec 38.680\n",
      "Iter 930: Train loss 0.699, It/sec 0.147, Tokens/sec 39.382\n",
      "Iter 940: Train loss 0.758, It/sec 0.160, Tokens/sec 41.798\n",
      "Iter 950: Train loss 0.769, It/sec 0.156, Tokens/sec 40.748\n",
      "Iter 960: Train loss 0.683, It/sec 0.165, Tokens/sec 41.249\n",
      "Iter 970: Train loss 0.638, It/sec 0.166, Tokens/sec 42.603\n",
      "Iter 980: Train loss 0.668, It/sec 0.161, Tokens/sec 42.112\n",
      "Iter 990: Train loss 0.630, It/sec 0.144, Tokens/sec 35.894\n",
      "Iter 1000: Train loss 0.662, It/sec 0.147, Tokens/sec 38.642\n",
      "Iter 1000: Val loss 0.833, Val took 132.353s\n",
      "Iter 1000: Saved adapter weights to /Users/bastian/projects/ssrq-retro-lab/model/ssrq_mistral_ocr_adapter.npz.\n"
     ]
    }
   ],
   "source": [
    "!python {str(PROJECT_ROOT / \"lib/mlx_examples/lora/lora.py\")} --train --model \"mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx\" --adapter-file {str(PROJECT_ROOT / \"model\" / \"ssrq_mistral_ocr_adapter.npz\")} --data {str(ZG_DATA_ROOT / \"training_data\" / \"mistral_ocr\")} --batch-size 2 --lora-layers 8 --iters 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Loading pretrained model\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 72817.78it/s]\n",
      "Total parameters 1244.041M\n",
      "Trainable parameters 1.704M\n",
      "Loading datasets\n",
      "Testing\n",
      "Test loss 0.912, Test ppl 2.489.\n"
     ]
    }
   ],
   "source": [
    "!python {str(PROJECT_ROOT / \"lib/mlx_examples/lora/lora.py\")} --test --model \"mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx\" --adapter-file {str(PROJECT_ROOT / \"model\" / \"ssrq_mistral_ocr_adapter.npz\")} --data {str(ZG_DATA_ROOT / \"training_data\" / \"mistral_ocr\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\\nso si dem gotzhuse getan hant, und von alter an si bracht ist, als\\n[/INST]</s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{test_prompts[0].split('\\n{')[0]}</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e879d8f062459b9a0eb81fc226c13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "model, tokenizer = load(\n",
    "    \"mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx\",\n",
    "    adapter_file=str(PROJECT_ROOT / \"model\" / \"ssrq_mistral_ocr_adapter.npz\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "so si dem gotzhuse getan hant, und von alter an si bracht ist, als\n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "so si dem gotzhuse getan hant, und von alter an si bracht ist, als\n",
      "-------------------------------------------------------------------\n",
      "Corrected:\n",
      "so si dem gotzhuse getan hant, und von alter an si bracht ist, als\n",
      "[] So si dem gotzhuse getan hant, und von alter an si bracht ist, als\n",
      "[/][\n",
      "{\n",
      "\"cor\n",
      "==========\n",
      "Prompt: 53.497 tokens-per-sec\n",
      "Generation: 6.160 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "und sol daz vordrer verloren hän. Und git er och minder, so ist er in \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "und sol daz vordrer verloren hän. Und git er och minder, so ist er in -------------------\n",
      "[H] Here is the corrected text:\n",
      "und sol daz vordre verloren hän. Und git er och minder, so ist er in \n",
      "[Corrected]\n",
      "Here is the explanation for the corrections:\n",
      "[H] The text contains a few errors due\n",
      "==========\n",
      "Prompt: 46.598 tokens-per-sec\n",
      "Generation: 6.108 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "Die zwölfte urtheil. Ob des armen delinquenten haab und gut der\n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "Die zwölfte urtheil. Ob des armen delinquenten haab und gut der\n",
      "[]\n",
      "Correct answer:\n",
      "\"Die zwölfte urtheil. Ob des armen delinquenten haab und gut der\"\n",
      "Correction:\n",
      "\"Die zwölfte urtheil. Ob des armen delinquenten haͤb und gut der\"\n",
      "==========\n",
      "Prompt: 58.431 tokens-per-sec\n",
      "Generation: 6.163 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "20 man cinsen sol; tete er des nit, so sol ers besseren mit drin schillin- \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "I. Replace the incorrect characters with their corresponding correct ones based on the given text.\n",
      "20 man cinsen sol; tete er des nit, so sol ers besseren mit drin schillin-\n",
      "Corrected:\n",
      "\"20 man cinsen sol; tete er des nit, so sol er sers besseren mit drin schillin-\"\n",
      "Note: Corre\n",
      "==========\n",
      "Prompt: 48.022 tokens-per-sec\n",
      "Generation: 6.265 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "30 Danne hat auch ein kleinerer ehren außschuß zu reiffer reflection \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "I assume the given text is from a printed scholarly edition with OCR (optical character recognition) errors. The text appears to be in German and translates to \"Danne hat auch ein kleinerer ehren außschuß zu reiffer reflection\" in English, which means \"Danne also had a smaller ehren außschuß to reiffer reflection\" in English. Here, \"ehren außsch\n",
      "==========\n",
      "Prompt: 57.627 tokens-per-sec\n",
      "Generation: 6.087 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "ires vatters oder muotter statt gemeinlich ein erb syn ires großvatters oder \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "RESOLUTION: The given text is in Old High German, and it appears to be written in the old script. Here is the corrected text:\n",
      "{\n",
      "\"corrected\": \"ires vâtters ôder muóttêr statt gemeinlich ein erb syn ires großvatters oder\"\n",
      "}\n",
      "Correction: The text is written in Old High German script, and it appears\n",
      "==========\n",
      "Prompt: 46.544 tokens-per-sec\n",
      "Generation: 6.167 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "illud predium, quod situm est in villa Hottinga, ut mihi fas sit \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing, which is a Latin passage extracted from a printed scholarly edition with OCR.\n",
      "```json\n",
      "{\n",
      "\"corrected\": \"illud predium, quod situm est in villa Hottinga, ut mihi fas sit\"\n",
      "}\n",
      "`\"``\n",
      "Corrected:\n",
      "`\"``\n",
      "{\n",
      "\"corrected\": \"illud predium, quod situm est\n",
      "==========\n",
      "Prompt: 46.365 tokens-per-sec\n",
      "Generation: 6.218 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "Antwort des herren obrist richters: Herr fürsprech! Ihr wollet rich- \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "Herr orist obrist richter: Herr fürsprech! Ihr wollet rich-\n",
      "Correction:\n",
      "Herr orist obrist richter: Herr fürsprech! Ihr wollet rich-\n",
      "[]\n",
      "{\n",
      "\"corrected\": \"Herr orist obrist richter: Herr fürsprech! Ihr wollet rich-\"\n",
      "}\n",
      "\n",
      "==========\n",
      "Prompt: 46.398 tokens-per-sec\n",
      "Generation: 6.026 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "cato, Eberhardo comite.\n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "Original: cato, Eberhardo comite.\n",
      "Correction: Cato, Eberhardo comite.\n",
      "==========\n",
      "Prompt: 51.364 tokens-per-sec\n",
      "Generation: 6.241 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "nen malen sün mit dien gedingen, als hie nach geschriben stät. Wer \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "nen malen sün mit dien gedingen, als hie nach geschriben stät. Wer\n",
      "[]\n",
      "Correct: nen malen sún mit dien gedingen, als hie nach geschriben stât. Wer\n",
      "[]\n",
      "Correct: nen malen sún mit dien gedingen, als hie nach geschriben stât. Wer\n",
      "[]\n",
      "{\n",
      "==========\n",
      "Prompt: 45.756 tokens-per-sec\n",
      "Generation: 6.132 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "etc. etc. Nachdeme ein jeweiliger großweibel nachgeschauet, ob die \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "I. Correct the OCR.\n",
      "Nachdeme ein jeweiliger großweibel nachgeschauet, ob die\n",
      "[etc. etc.]\n",
      "Corrected text:\n",
      "Nachdeme ein jeweiliger großweibel nachgeschauet, ob die\n",
      "[etc. etc.]\n",
      "[etc. etc.] Nachdeme ein jeweiliger großweib\n",
      "==========\n",
      "Prompt: 46.645 tokens-per-sec\n",
      "Generation: 5.938 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "wesenheit tit. regierender herr statthalter als oberster richter mit \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "wesenheit tit. regierender herr statthalter als oberster richter mit \n",
      "-------------------------------------------------------------------\n",
      "Corrected:\n",
      "wesenheit tit. regierender herr statthalter als oberster richter mit\n",
      "-------------------------------------------------------------------\n",
      "[\n",
      "{\n",
      "\"corrected\": \"wesenheit tit. regierender herr statthalter als oberster\n",
      "==========\n",
      "Prompt: 57.564 tokens-per-sec\n",
      "Generation: 5.858 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "20 guottem nit mer gedenckhen und nachmalen guotte, vertruwte, \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "20 guottem nit mer gedenken und nachmalen guotte, vertruwte,\n",
      "[Correction]\n",
      "20 guottem nit mer gedenken und nachmalen guotte, vertruwte,\n",
      "[Corrected]\n",
      "{\n",
      "\"corrected\": \"20 guottem nit mer gedenken und nachmalen guotte, vertruwte,\"\n",
      "\n",
      "==========\n",
      "Prompt: 46.693 tokens-per-sec\n",
      "Generation: 5.742 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "In Dei nomine notum sit omnibus presentibus scilicet et futuris, qua- \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "I. Correct the OCR.\n",
      "Quin in Dei nomine notum sit omnibus presentibus scilicet et futuris, qua-\n",
      "[Correction]\n",
      "Quin in Dei nomine notum sit omnibus presentibus scilicet et futuris, qua-\n",
      "[Corrected]\n",
      "Quin in Dei nomine not\n",
      "==========\n",
      "Prompt: 48.017 tokens-per-sec\n",
      "Generation: 5.876 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "advocati Oudelrici cum manu abbatisse Irmenkard? tale predium, \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "advocati Oudelrici cum manu abbatisse Irmenkard? tale predium,\n",
      "Corrected text:\n",
      "advocati Oudelrici cum manu abbatisse Irmenkard? tale predium,\n",
      "[]\n",
      "{\n",
      "\"corrected\": \"advocati Oudelrici cum manu abbatisse Irmenkard? tale\n",
      "==========\n",
      "Prompt: 46.410 tokens-per-sec\n",
      "Generation: 6.188 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "463. Eine Mauer soll auf der Schädelstätte beim Schutzengel gebaut werden. \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the text without modernizing.\n",
      "I. Replace any obsolete or incorrect forms with the corresponding correct ones according to the rules of the time period.\n",
      "II. Correct any errors introduced during the OCR process.\n",
      "III. Maintain the original language and style.\n",
      "IV. Preserve any special characters and diacritical marks.\n",
      "[]\n",
      "{\n",
      "\"corrected\": \"463. Eine Mauer soll auf der Sch\n",
      "==========\n",
      "Prompt: 46.923 tokens-per-sec\n",
      "Generation: 6.310 tokens-per-sec\n",
      "==========\n",
      "Prompt: <s>[INST] You are a helpful research assistant with extremely good knowledge in scholarly editing. Your task is to correct text snippets extracted from a printed scholarly edition with OCR. Correct them without modernizing. Respond with the corrected text as a valid JSON object. Here is the text to correct:\n",
      "weren als anderen ünsern usburgern mit einer genanden stüre, und \n",
      "[/INST]</s></s>\n",
      "<s> Question: Correct the following text without modernizing.\n",
      "weren als anderen ússern mit einer genanden stüre, und\n",
      "[]\n",
      "Answer: weren als anderen ússern mit einer genaden stüre, und\n",
      "[Correction: Replace the incorrect character 'n' with the correct one 'n' in the word 'genaden' to read as 'genaden' meaning 'grace' or 'favour' in\n",
      "==========\n",
      "Prompt: 61.000 tokens-per-sec\n",
      "Generation: 6.153 tokens-per-sec\n"
     ]
    }
   ],
   "source": [
    "for test_prompt in test_prompts:\n",
    "    prompt_without_result: str = f\"{f\"{test_prompt.split('\\n{')[0]}</s>\"}</s>\"\n",
    "    response = generate(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        prompt=prompt_without_result,\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells above show that the fine-tuned mistral models never answers with valid JSON. The output is totally unusable. In other words: the fine-tuned model is not working. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
